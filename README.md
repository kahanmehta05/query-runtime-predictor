
# ğŸš€ Query Runtime Predictor

A machine learning-based system to predict the runtime of SQL queries executed on PostgreSQL, built using TPC-H benchmark queries.

---

## ğŸ“¦ Project Structure

```
query-runtime-predictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ final_features_sample.csv        # Extracted features from queries
â”‚   â”œâ”€â”€ final_features_extended.csv      # Features from extended queries
â”‚   â”œâ”€â”€ final_features_all.csv           # Merged dataset (1â€“222 queries)
â”‚   â””â”€â”€ processed/                       # JSON plan files (1â€“22)
â”‚   â””â”€â”€ processed_extended/              # JSON plan files (23â€“222)
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ create_tpch_schema.sql
â”‚   â”œâ”€â”€ load_tpch_data.sql
â”‚   â””â”€â”€ queries/                         # All SQL queries (Q1 to Q222)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_runtime_features.py      # Runs query and logs plan (JSON)
â”‚   â”œâ”€â”€ extract_features_sample.py       # Extracts features â†’ CSV
â”‚   â”œâ”€â”€ run_all_queries.py
â”‚   â”œâ”€â”€ run_missing_queries.py
â”‚   â””â”€â”€ split_new_queries.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ ...                              # For model training/analysis
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ...                              # Trained models or saved checkpoints
â””â”€â”€ venv/                                # Python virtual environment
```

---

## ğŸ”§ Setup Instructions (Any System)

### 1. ğŸ“¥ Clone the Repository
```bash
git clone https://github.com/kahanmehta05/query-runtime-predictor.git
cd query-runtime-predictor
```

### 2. ğŸ Setup Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. ğŸ“¦ Install Dependencies
```bash
pip install pandas psycopg2-binary psutil
```

If `requirements.txt` exists:
```bash
pip install -r requirements.txt
```

---

## ğŸ›  PostgreSQL Setup

### 1. Launch PostgreSQL and Create Database
```sql
CREATE DATABASE tpch;
```

### 2. Create Schema and Load Data
Inside `psql`:
```bash
\i db/create_tpch_schema.sql
\i db/load_tpch_data.sql
```

---

## ğŸ“¤ Run Scripts

### 1. Extract Runtime & Plan (for selected queries)
```bash
python scripts/extract_runtime_features.py --queries 1 2 3
```

### 2. Extract Features into CSV
```bash
python scripts/extract_features_sample.py
```

This generates `data/final_features_sample.csv`.

---

## âš™ï¸ Features Extracted

Includes both query-level and hardware-level features:
- Total cost
- Node counts (Seq Scan, Nested Loop, etc.)
- Cardinality error
- Actual vs estimated rows
- Query text
- Plan tree
- CPU cores, threads, RAM, frequency, disk I/O

---

## ğŸŒ Running on Another Machine

1. Clone the repo
2. Setup virtual env
3. Run:
   ```bash
   python scripts/extract_runtime_features.py
   python scripts/extract_features_sample.py
   ```
4. Push changes:
   ```bash
   git add data/final_features_sample.csv
   git commit -m "Added features from M2 Mac"
   git push
   ```

---

## ğŸ¤ Contributing
1. Fork the repo
2. Create a new branch
3. Push and create a PR

---

## ğŸ‘¨â€ğŸ”¬ Authors
- Kahan Mehta
- [Any collaborators here]

---

## ğŸ§  Research Goal
To build a machine-learning model that predicts query runtime across:
- Different hardware
- Different datasets
- Different query complexities

---

## ğŸ“„ License
MIT License (optional)

---
